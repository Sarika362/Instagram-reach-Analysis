# -*- coding: utf-8 -*-
"""Instagram_Reach_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17vQAbLsxotB5u7yyC4AqsbQvXII_JVqz
"""

pip install pandas numpy matplotlib seaborn plotly_express wordcloud

"""#1. Analyzing the reach of my Instagram account by importing the necessary Python libraries and the dataset."""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

"""#Read the data from the csv file"""

dataset = pd.read_csv("Instagram data.csv", encoding = 'latin1')
print(dataset)
print()
dataFrame =pd.DataFrame(dataset)
print(dataFrame)

"""---
#2. Check for null / nan values and drop if you find any
"""

print(dataset.isnull())
print(dataset.isnull().sum())
print()
#there is no null values

dataset.info()

"""---
#3. Analyze the distribution of impressions received from home and display it using the distplot of  seaborn.
"""

plt.figure(figsize=(10, 10))
plt.style.use('fivethirtyeight')
plt.title("Distribution of Impressions from Home")
sns.distplot(dataset['From Home'])
plt.show()

"""---
#4. Analyze the distribution of the impressions received from hashtags and display it using the distplot of seaborn.
"""

plt.figure(figsize=(10, 10))
plt.title("Distribution of Impressions from Hashtags")
sns.distplot(dataset['From Hashtags'])
plt.show()

"""---
#5.Analyze the distribution of the impressions received from the explore section and display it using the distplot of seaborn.
"""

plt.figure(figsize=(10, 10))
plt.title("Distribution of Impressions from Explore")
sns.distplot(dataset['From Explore'])
plt.show()

"""---
#6.Analyze the percentage of impressions received from various sources and display it as pie chart.
"""

#6.Analyze the percentage of impressions received from various sources and display it as pie chart.
home = dataset["From Home"].sum()
hashtags = dataset["From Hashtags"].sum()
explore = dataset["From Explore"].sum()
other = dataset["From Other"].sum()
Saves = dataset["Saves"].sum()
Comments = dataset["Comments"].sum()
Shares = dataset["Shares"].sum()
Shares = dataset["Shares"].sum()
Likes = dataset["Likes"].sum()
Profile_Visits = dataset["Profile Visits"].sum()
Follows = dataset["Follows"].sum()
labels = ['From Home', 'From Hashtags', 'From Explore', 'Other','From Saves','From Comments','From Shares',"From Likes","From Profile Visits","From Follows"]
values = [home, hashtags, explore, other,Saves,Comments,Shares,Likes,Profile_Visits,Follows]

fig = px.pie(dataset, values=values, names=labels, color_discrete_sequence=px.colors.sequential.BuPu_r,
             title='Impressions on Instagram Posts From Various Sources')
fig.update_traces(pull=[0.1, 0, 0, 0])
fig.show()
print()

"""---
#7. Create a wordcloud of the caption column to look at the most used words in the caption of Instagram posts.
"""

text = " ".join(i for i in dataset.Caption)
stopwords = set(STOPWORDS)
wordcloud = WordCloud(stopwords=stopwords, background_color="white", colormap="tab10").generate(text)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()
print()

"""---
#8. Create a wordcloud of the hashtags column to look at the most used hashtags in Instagram posts.
"""

text = " ".join(i for i in dataset.Hashtags)
stopwords = set(STOPWORDS)
wordcloud = WordCloud(stopwords=stopwords, background_color="white", collocations = False, mode='RGBA', colormap='Set3').generate(text)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud, interpolation='blackman')
plt.axis("off")
plt.show()
print()

"""---
#9.Analyze the relationship between the number of likes and the number of impressions on Instagram posts and display it as scatter chart.
"""

figure_1 = px.scatter(dataFrame, x="Impressions",
                    y="Likes", size="Likes", trendline="ols",
                    title = "Relationship Between Likes and Impressions")
figure_1.show()
print()

"""---
#10.Analyze the relationship between the number of comments and the number of impressions on Instagram posts and display it as scatter chart.
"""

figure_2 = px.scatter(dataFrame, x="Impressions",
                    y="Comments", size="Comments", trendline="ols",
                    title = "Relationship Between Comments and Total Impressions")
figure_2.show()
print()

"""---
#11.Analyze the relationship between the number of shares and the number of impressions and display it as scatter chart.
"""

figure_3 = px.scatter(dataFrame, x="Impressions",y="Shares",
                    size="Shares", trendline="ols",
                    title = "Relationship Between Shares and Total Impressions")
figure_3.show()
print()

"""---
#12. Analyze the relationship between the number of saves and the number of impressions and display it as scatter chart.
"""

figure_3 = px.scatter(dataFrame, x="Impressions",y="Saves",
                    size="Shares", trendline="ols",
                    title = "Relationship Between Saves and Total Impressions")
figure_3.show()
print()

data = pd.read_csv("Instagram data.csv", encoding = 'latin1')
print(data.head())
data = data.dropna()
data = data.iloc[:, :-2]
correlation = data.corr()
print(correlation["Impressions"].sort_values(ascending=False))

"""Analyzing Conversion Rate"""

conversion_rate = (data["Follows"].sum() / data["Profile Visits"].sum()) * 100
print(conversion_rate)

figure = px.scatter(data_frame = data, x="Profile Visits",
                    y="Follows", size="Follows", trendline="ols",
                    title = "Relationship Between Profile Visits and Followers Gained")
figure.show()

"""Instagram Reach Prediction Model"""

x = np.array(data[['Likes', 'Saves', 'Comments', 'Shares',
                   'Profile Visits', 'Follows']])
y = np.array(data["Impressions"])

from sklearn.model_selection import train_test_split
from sklearn.linear_model import PassiveAggressiveRegressor
from sklearn.metrics import accuracy_score
xtrain, xtest, ytrain, ytest = train_test_split(x, y,
                                                test_size=0.15,
                                                random_state=42)

model = PassiveAggressiveRegressor()
model.fit(xtrain, ytrain)
model.score(xtest, ytest)